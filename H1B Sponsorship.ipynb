{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H1B Sponsorsip: Big-Name Compaines v.s. Start-ups\n",
    "\n",
    "As an international student who just started the Master of Science in Business Analytics, I have an ultimate goal of finding a data analyst job within the US. Past experience told me that I have liked the atmosphere and style of start-ups better. However, I have also heard a lot that with limited resource, start-ups tend not to hire international students who need H1B sponsorship. Thus began my research: What is the H1B application like when taking company size into consideration? Do titles give a huge difference in salary? What are my best chance to land a job in the US?\n",
    "\n",
    "In order to answer my question, I utilized the technique of web scraping on [H1B Salary Database](https://h1bdata.info/index.php)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import us\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving Data Needed\n",
    "\n",
    "Since different companies with different job titles might be doing similar work, I have chosen a few common job titles for MSBA students, including:\n",
    "\n",
    "* Analyst\n",
    "* Data Analyst\n",
    "* Business Analyst\n",
    "* Business Intelligence Engineer\n",
    "* Business Intelligence Developer\n",
    "* Business Intelligence Analyst\n",
    "* Data Scientist\n",
    "* Data Scientist Analyst\n",
    "* Data Specialist\n",
    "* Business Data Analyst\n",
    "\n",
    "Since there are unlimited job titles that are possible, above mentioned are just a few more common ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the list of desired job title search url\n",
    "urls = ['https://h1bdata.info/index.php?em=&job=analyst&city=&year=All+Years',\n",
    "        'https://h1bdata.info/index.php?em=&job=data+analyst&city=&year=All+Years', \n",
    "        'https://h1bdata.info/index.php?em=&job=business+analyst&city=&year=All+Years', \n",
    "        'https://h1bdata.info/index.php?em=&job=Business+Intelligence+Engineer&city=&year=All+Years', \n",
    "        'https://h1bdata.info/index.php?em=&job=Business+Intelligence+Developer&city=&year=All+Years',\n",
    "        'https://h1bdata.info/index.php?em=&job=Business+Intelligence+Analyst&city=&year=All+Years',\n",
    "        'https://h1bdata.info/index.php?em=&job=Data+Scientist+I&city=&year=All+Years', \n",
    "        'https://h1bdata.info/index.php?em=&job=Data+Scientist+1&city=&year=All+Years', \n",
    "        'https://h1bdata.info/index.php?em=&job=Data+Scientist+Analyst&city=&year=All+Years', \n",
    "        'https://h1bdata.info/index.php?em=&job=Data+Specialist&city=&year=All+Years', \n",
    "        'https://h1bdata.info/index.php?em=&job=Business+Data+Analyst&city=&year=All+Years']\n",
    "\n",
    "#url = 'https://h1bdata.info/index.php?em=&job=data+analyst&city=&year=All+Years'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving: https://h1bdata.info/index.php?em=&job=analyst&city=&year=All+Years\n",
      "Total Records: 19106\n",
      "Retrieving: https://h1bdata.info/index.php?em=&job=data+analyst&city=&year=All+Years\n",
      "Total Records: 27168\n",
      "Retrieving: https://h1bdata.info/index.php?em=&job=business+analyst&city=&year=All+Years\n",
      "Total Records: 61903\n",
      "Retrieving: https://h1bdata.info/index.php?em=&job=Business+Intelligence+Engineer&city=&year=All+Years\n",
      "Total Records: 62222\n",
      "Retrieving: https://h1bdata.info/index.php?em=&job=Business+Intelligence+Developer&city=&year=All+Years\n",
      "Total Records: 63537\n",
      "Retrieving: https://h1bdata.info/index.php?em=&job=Business+Intelligence+Analyst&city=&year=All+Years\n",
      "Total Records: 67897\n",
      "Retrieving: https://h1bdata.info/index.php?em=&job=Data+Scientist+I&city=&year=All+Years\n",
      "Total Records: 68286\n",
      "Retrieving: https://h1bdata.info/index.php?em=&job=Data+Scientist+1&city=&year=All+Years\n",
      "Total Records: 68407\n",
      "Retrieving: https://h1bdata.info/index.php?em=&job=Data+Scientist+Analyst&city=&year=All+Years\n",
      "Total Records: 68466\n",
      "Retrieving: https://h1bdata.info/index.php?em=&job=Data+Specialist&city=&year=All+Years\n",
      "Total Records: 68928\n",
      "Retrieving: https://h1bdata.info/index.php?em=&job=Business+Data+Analyst&city=&year=All+Years\n",
      "Total Records: 69705\n"
     ]
    }
   ],
   "source": [
    "#using for loop to retrieve data \n",
    "\n",
    "record = []\n",
    "\n",
    "for url in urls:\n",
    "    print('Retrieving:', url)\n",
    "    html = urlopen(url).read()\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    data = soup.tbody.find_all(\"tr\")\n",
    "\n",
    "    #finding all \"td\" in html since \"td\" tag represents data I need\n",
    "    for index in range(len(data)):\n",
    "        for td in data[index].find_all(\"td\"):\n",
    "            try:\n",
    "                record.append(td.text.replace('\\n', ' ').strip())\n",
    "            except:\n",
    "                continue\n",
    "    print('Total Records:', int(len(record)/7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning scraped data by reshaping and deleting unwanted rows\n",
    "data = np.reshape(record, (int(len(record)/7) ,7))\n",
    "df = pd.DataFrame(data, columns = ['name', 'title', 'base_salary', 'location', 'submit_date', 'start_date', 'status'])\n",
    "\n",
    "df['name'] = df['name'].str.title()\n",
    "df['title'] = df['title'].str.title()\n",
    "df['status'] = df['status'].str.title()\n",
    "\n",
    "df['base_salary'] = df['base_salary'].str.replace(',', '')\n",
    "df['base_salary'] = df['base_salary'].astype(int)\n",
    "\n",
    "df['submit_date'] = pd.to_datetime(df['submit_date'])\n",
    "df['start_date'] = pd.to_datetime(df['start_date'])\n",
    "\n",
    "df['location'] = df['location'].str.split(',')\n",
    "df['city'] = df['location'].str[0]\n",
    "df['city'] = df['city'].str.title()\n",
    "df['state'] = df['location'].str[1]\n",
    "df['state'] = df['state'].str.strip()\n",
    "df['city'] = df['city'].str.strip()\n",
    "#mapping US states to full name using us package\n",
    "df['state'] = df['state'].map(us.states.mapping('abbr', 'name')).fillna(df['state']).str.title()\n",
    "\n",
    "#clean error data in state column and remove unwanted\n",
    "df.loc[df['state'] == 'San Ramon', 'state'] = 'California'\n",
    "df.loc[df['state'] == 'Ca 95134', 'state'] = 'California'\n",
    "df.loc[df['state'] == 'Ca 90802', 'state'] = 'California'\n",
    "df.loc[df['state'] == 'Woodland Hills', 'state'] = 'California'\n",
    "df.loc[df['state'] == 'Dc 20006', 'state'] = 'District Of Columbia'\n",
    "df.loc[df['state'] == 'D.C.', 'state'] = 'District Of Columbia'\n",
    "df.loc[df['state'] == 'Ets Drive', 'state'] = 'New Jersey'\n",
    "df.loc[df['state'] == 'Mo 63105', 'state'] = 'Missouri'\n",
    "df.loc[df['state'] == 'Minneapolis', 'state'] = 'Minnesota'\n",
    "df.loc[df['state'] == 'Long Island City', 'state'] = 'New York'\n",
    "df.loc[df['state'] == 'Atlanta', 'state'] = 'Georgia'\n",
    "df = df[df['state'] != '']\n",
    "df = df[df['state'] != 'Puerto Rico']\n",
    "df = df[df['state'] != 'Guam']\n",
    "df = df[df['state'] != 'Virgin Islands']\n",
    "df['state'] = df['state'].astype('category')\n",
    "\n",
    "df['name'] = df['name'].str.replace('Ltd', '')\n",
    "df['name'] = df['name'].str.replace('Llc', '')\n",
    "df['name'] = df['name'].str.replace('Inc', '')\n",
    "df['name'] = df['name'].str.strip()\n",
    "\n",
    "#remove location column since no longer needed\n",
    "df.drop(columns = ['location'], inplace = True)\n",
    "df['category'] = None\n",
    "\n",
    "#select only the ones that are submitted after 2018-01-01\n",
    "df = df[df['submit_date'] >= '2018-01-01'].reset_index(drop = True)\n",
    "\n",
    "#consider ones that have more than 20 applications since 2018\n",
    "count = df.groupby('name').count().sort_values('title', ascending = False)\n",
    "select = count[count['title'] >= 20].index.tolist()\n",
    "result = df[df['name'].isin(select)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>base_salary</th>\n",
       "      <th>submit_date</th>\n",
       "      <th>start_date</th>\n",
       "      <th>status</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rizontek</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>54000</td>\n",
       "      <td>2020-05-06</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>Certified</td>\n",
       "      <td>Austin</td>\n",
       "      <td>Texas</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rizontek</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>54000</td>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>Certified</td>\n",
       "      <td>Austin</td>\n",
       "      <td>Texas</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rizontek</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>54000</td>\n",
       "      <td>2019-02-15</td>\n",
       "      <td>2019-08-17</td>\n",
       "      <td>Certified</td>\n",
       "      <td>Syracuse</td>\n",
       "      <td>New York</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rizontek</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>56000</td>\n",
       "      <td>2019-02-14</td>\n",
       "      <td>2019-08-16</td>\n",
       "      <td>Certified</td>\n",
       "      <td>Austin</td>\n",
       "      <td>Texas</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turnberry Solutions</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>56020</td>\n",
       "      <td>2019-11-05</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>Certified</td>\n",
       "      <td>Malvern</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17691</th>\n",
       "      <td>Tribolatech</td>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>120000</td>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>Certified</td>\n",
       "      <td>Tempe</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17692</th>\n",
       "      <td>Tribolatech</td>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>120000</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>Certified</td>\n",
       "      <td>Tempe</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17693</th>\n",
       "      <td>Intuit</td>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>120967</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>2019-05-15</td>\n",
       "      <td>Certified</td>\n",
       "      <td>Mountain View</td>\n",
       "      <td>California</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17694</th>\n",
       "      <td>Exzac</td>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>125000</td>\n",
       "      <td>2020-09-09</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>Certified</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17695</th>\n",
       "      <td>Jpmorgan Chase &amp; Co</td>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>134191</td>\n",
       "      <td>2018-05-24</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>Certified</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17696 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name                  title  base_salary submit_date  \\\n",
       "0                 Rizontek                Analyst        54000  2020-05-06   \n",
       "1                 Rizontek                Analyst        54000  2020-05-14   \n",
       "2                 Rizontek                Analyst        54000  2019-02-15   \n",
       "3                 Rizontek                Analyst        56000  2019-02-14   \n",
       "4      Turnberry Solutions                Analyst        56020  2019-11-05   \n",
       "...                    ...                    ...          ...         ...   \n",
       "17691          Tribolatech  Business Data Analyst       120000  2020-03-23   \n",
       "17692          Tribolatech  Business Data Analyst       120000  2020-03-25   \n",
       "17693               Intuit  Business Data Analyst       120967  2019-05-09   \n",
       "17694                Exzac  Business Data Analyst       125000  2020-09-09   \n",
       "17695  Jpmorgan Chase & Co  Business Data Analyst       134191  2018-05-24   \n",
       "\n",
       "      start_date     status           city         state category  \n",
       "0     2020-10-01  Certified         Austin         Texas     None  \n",
       "1     2020-10-01  Certified         Austin         Texas     None  \n",
       "2     2019-08-17  Certified       Syracuse      New York     None  \n",
       "3     2019-08-16  Certified         Austin         Texas     None  \n",
       "4     2020-01-01  Certified        Malvern  Pennsylvania     None  \n",
       "...          ...        ...            ...           ...      ...  \n",
       "17691 2020-04-13  Certified          Tempe       Arizona     None  \n",
       "17692 2020-04-13  Certified          Tempe       Arizona     None  \n",
       "17693 2019-05-15  Certified  Mountain View    California     None  \n",
       "17694 2020-10-01  Certified       New York      New York     None  \n",
       "17695 2018-10-31  Certified    Jersey City    New Jersey     None  \n",
       "\n",
       "[17696 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result.reset_index()\n",
    "result.drop(labels='index', axis='columns', inplace=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tuples in matches:\n",
    "    if tuples[1] >= 80:\n",
    "        print(tuples[0], matches[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is This Company A Start-up or A Big-Name?\n",
    "\n",
    "In order to decide whether or not the company is a \"big-name\" company, I decided to utilize the information on Wikipedia regarding [unicorn start-up companies](https://en.wikipedia.org/wiki/List_of_unicorn_startup_companies) and [2019 Fortune 500 companies](https://docs.google.com/spreadsheets/d/1SlNYZxOvpuQejYWhM7S81v3Hi_BqfbynVqwiS_XUTBI/edit#gid=0) (parsed by [Ashely Ng on towards data science](https://towardsdatascience.com/scraping-the-fortune-500-company-job-boards-step-by-step-a124cf8bc364))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = pd.Series(df['name'].unique()).tolist()\n",
    "list.sort()\n",
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
